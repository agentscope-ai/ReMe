训练-推理不一致的主要来源
# 3.1 系统设计的根本矛盾
# ● 引擎目标冲突：
#   ○ 推断引擎（如 vLLM、TensorRT-LLM）：追求吞吐量，采用低精度（INT8/FP8）、定制内核（如 speculative decoding）、非确定性计算路径
#   ○ 训练框架（如 FSDP、DeepSpeed）：依赖高精度（FP32/混合精度）、确定性计算，保证梯度稳定
#   ○ 结果：推断与训练阶段的计算路径不一致，导致梯度更新公式存在偏差（∇θvLLM ≠ ∇θFSDP）
# 3.2 数据与内容触发因素
# ● 低概率 Token 生成：
#   ○ 多轮推理、工具调用等场景下，模型被迫生成低概率 Token
#   ○ 推断阶段采样到低概率 Token，训练阶段概率更低，导致重要性权重极低，易触发梯度爆炸（参考 3.3 The Smoking Gun）
# ● 分布外（OOD）内容暴露：
#   ○ 工具响应（如  结构化文本）超出预训练分布，生成更多低概率 Token
#   ○ 多轮交互，非第一轮输出的 mismatch 更高（见图4）
# 3.3 硬件环境变量影响
# ● GPU 架构差异：
#   ○ 不匹配程度：A100 > L20 > H20
#   ○ 物理根源：不同 GPU 的低精度实现、内核优化策略（如 cascade attention）
# ● 动态环境反馈：
#   ○ 相同代码在不同硬件表现差异大（如图8 L20 崩溃，H20 恢复）
# 3.4 训练动态恶化机制
# ● 数值敏感性 → 内核误差放大：
#   ○ RL 优化将参数推向 bfloat16 的极值区
#   ○ 推断与训练引擎的不同计算顺序放大误差，形成螺旋崩溃（见图10）
# ● 自强化崩溃循环：
#   ○ 初始 mismatch 产生高误差 batch，进一步恶化模型状态，持续生成高 mismatch 批次（见图9）